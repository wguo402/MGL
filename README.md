# MGL
MGL-Meta-Graph-Learning-for-Few-Shot-Food-Recognition
Food recognition has attracted increasing attention in image processing, computer vision and multimedia in the last few years. As a special recognition task, beside the similarity as traditional object recognition, the food recognition suffers from three challenging problems: shot of distinctive spatial layout and configuration of food images, intra-category appearance more differences than its inter-category counterparts and hard to extrapolate new food category outside of the domain of supervised samples provided.

To overcome the above issues, we address the problem of food recognition from the view of few shot learning prospective. In this paper, we propose a Meta Graph Learning (MGL) to solve the above problems concurrently in one framework. Our algorithm integrates meta learning to exploit powerful multiple sources of information with few samples. Moreover, meta learning leverages the unlabeled query set and support set with a meta-optimization objective, which can make our model have the ability to learn new concepts on unseen domain. In order to alleviate
the poverty of semantic information in food recognition, we construct a graph neural network module to delineate coordinates and semantics mapping of food images in meta learning processing. We conduct extensive experiments on a number of datasets and show the meta graph learning can bring consistent performance boost for a wide range of backbones on food recognition. Our experimental results demonstrate that GML1significantly outperforms the state-of-the-art food recognition methods on a number of benchmarks. The code and model will be publicly available accompanying this paper.
 
This code is only to give paper reviewers a verification and academic research. After the paper is accepted, we will polish and optimize the code.
